{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Stanza parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "# stanza.download('en') # download English model\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse') # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "        \"hell yeah!\"\n",
    "        #  'The boss runs the company.',\n",
    "        #  'The company is run by the boss', \n",
    "        #  'The company is run in the dark.', \n",
    "        #  'He runs in the jungle.',\n",
    "        #  'The roads run through the city.',\n",
    "        #  'He runs his finger through his hair.',\n",
    "        #  'The computer runs fast.',\n",
    "        #  'The car runs really fast.'\n",
    "         ]\n",
    "\n",
    "# sents = ['MISS NORMAN : Will you do me the honour to meet me at the bridgehead at half-past nine practically at once ?']\n",
    "target = 'miss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    doc = nlp(sent) # run annotation over a sentence\n",
    "    print('sentence:', sent)\n",
    "    # print(doc)\n",
    "    # print(doc.entities)\n",
    "    print(*[f'word: {word.text}\\tlemma: {word.lemma}\\tpos: {word.pos}\\tid: {word.id}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')\n",
    "    print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from collections import defaultdict\n",
    "\n",
    "sents = ['The boss runs the company.',\n",
    "         'The company is run by the boss', \n",
    "         'The company is run in the dark.', \n",
    "         'He runs in the jungle.',\n",
    "         'The roads run through the city.',\n",
    "         'He runs his finger through his hair.',\n",
    "         'The computer runs fast.',\n",
    "         'The car runs really fast.']\n",
    "target = 'run'\n",
    "\n",
    "# 1. load the English pipeline (tokeniser-POS-lemma-dependency)\n",
    "nlp = stanza.Pipeline(\n",
    "        'en', processors='tokenize,pos,lemma,depparse',\n",
    "        tokenize_no_ssplit=True,  # treat each string as a single sentence\n",
    "        verbose=False)\n",
    "\n",
    "results = []               # (sent_id, dep_lemma, deprel)\n",
    "for sent_id, text in enumerate(sents, 1):\n",
    "    doc = nlp(text)\n",
    "    sent = doc.sentences[0]               # exactly one per string\n",
    "    for w in sent.words:                  # iterate over tokens/words\n",
    "        if w.lemma == target:             # <- our target lemma\n",
    "            head_id = w.id\n",
    "            # collect *immediate* dependents of this “run”\n",
    "            for d in sent.words:\n",
    "                if d.head == head_id:\n",
    "                    results.append((sent_id, d.lemma, d.deprel))\n",
    "\n",
    "# pretty-print\n",
    "for sent_id, lem, rel in results:\n",
    "    print(f'S{sent_id}: {lem:<10}  {rel}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sents = ['The boss runs the company.',\n",
    "#          'The company is run by the boss', \n",
    "#          'The company is run in the dark.', \n",
    "#          'He runs in the jungle.',\n",
    "#          'The roads run through the city.',\n",
    "#          'He runs his finger through his hair.',\n",
    "#          'The computer runs fast.',\n",
    "#          'The car runs really fast.'\n",
    "#          ]\n",
    "\n",
    "# sents = [\n",
    "#     \"Freedom is priceless.\",\n",
    "#     \"She fought for freedom during the revolution.\",\n",
    "#     \"The court finally granted him the freedom to speak openly.\",\n",
    "#     \"Within the classroom, freedom of thought nurtures creativity.\",\n",
    "#     \"The towering bronze sculpture, Freedom, dominates the plaza.\",\n",
    "#     \"After the last exam, the students burst outside in pure freedom.\",\n",
    "#     \"Digital tracking can quietly erode freedom online.\",\n",
    "#     \"We debated whether freedom or security mattered more.\",\n",
    "#     \"Without self-control, freedom often collapses into chaos.\",\n",
    "#     \"He inhaled deeply, freedom flooding his lungs at the prison gates.\"\n",
    "# ]\n",
    "\n",
    "# sents = [\n",
    "#     \"The table shook during the earthquake.\",\n",
    "#     \"She carved her initials into the wooden table.\",\n",
    "#     \"After dinner, they sat around the table and talked for hours.\",\n",
    "#     \"The architect presented a glass table as the room's centerpiece.\",\n",
    "#     \"Please table the motion until next week’s meeting.\",\n",
    "#     \"We sorted the data into a table for easier comparison.\",\n",
    "#     \"The cat leapt onto the table, knocking over a vase.\",\n",
    "#     \"Negotiators agreed to table further discussion until sunrise.\",\n",
    "#     \"Beneath the table, a hidden drawer contained old photographs.\",\n",
    "#     \"A picnic table stood alone under the oak tree.\"\n",
    "# ]\n",
    "\n",
    "sents = [\n",
    "    \"This article is interesting.\",\n",
    "    \"An interesting twist changed the plot completely.\",\n",
    "    \"He found the lecture interesting despite the late hour.\",\n",
    "    \"Someone interesting moved into the apartment next door.\",\n",
    "    \"The most interesting of the artifacts was the jade mask.\",\n",
    "    \"Keep your questions interesting and concise.\",\n",
    "    \"They made the workshop interesting by adding hands-on demos.\",\n",
    "    \"What I find interesting is how quickly trends shift.\",\n",
    "    \"Do you have anything interesting to read on the train?\",\n",
    "    \"Interesting, she thought, how silence can speak louder than words.\"\n",
    "]\n",
    "\n",
    "\n",
    "TARGET = 'interesting' \n",
    "\n",
    "MAX_DEPTH  = 2             # you can pass (1,), (2,), (1,2,3) …\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "        \"en\",\n",
    "        processors=\"tokenize,pos,lemma,depparse\",\n",
    "        tokenize_no_ssplit=True,\n",
    "        verbose=False)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "def collect_connected(sent, target_lemma, max_depth):\n",
    "    \"\"\"\n",
    "    Return {depth: [(lemma, path)]} where 'path' is a string like\n",
    "    '↓obj' or '↑nsubj:pass > ↓obl' showing the route from the target\n",
    "    to the node.  Traversal is undirected, up to max_depth edges.\n",
    "    \"\"\"\n",
    "    id2word   = {w.id: w for w in sent.words}\n",
    "    neighbours = defaultdict(list)                  # id -> [(word, label)]\n",
    "\n",
    "    # build bidirectional edges\n",
    "    for w in sent.words:\n",
    "        if w.head == 0:                             # ROOT has no parent\n",
    "            continue\n",
    "        head = id2word[w.head]\n",
    "        neighbours[w.id].append((head, f\"↑{w.deprel}\"))   # child -> parent\n",
    "        neighbours[head.id].append((w, f\"↓{w.deprel}\"))   # parent -> child\n",
    "\n",
    "    result = defaultdict(list)                      # depth -> [(lemma, path)]\n",
    "    for w in sent.words:\n",
    "        if w.lemma != target_lemma:\n",
    "            continue                                # other lemmas not our start\n",
    "        q = deque([(w, 0, [])])                     # node, depth, path so far\n",
    "        visited = {w.id}\n",
    "        while q:\n",
    "            node, d, path = q.popleft()\n",
    "            if d == max_depth:                      # stop expanding beyond limit\n",
    "                continue\n",
    "            for nb, rel in neighbours[node.id]:\n",
    "                if nb.id in visited:\n",
    "                    continue\n",
    "                nd     = d + 1\n",
    "                npath  = path + [rel]\n",
    "                result[nd].append((nb.lemma, \" > \".join(npath)))\n",
    "                visited.add(nb.id)\n",
    "                q.append((nb, nd, npath))\n",
    "    return result\n",
    "# ------------------------------------------------------------------ #\n",
    "\n",
    "all_hits = defaultdict(lambda: defaultdict(list))   # sent_id -> depth -> items\n",
    "for sid, text in enumerate(sents, 1):\n",
    "    sent = nlp(text).sentences[0]\n",
    "    dep_map = collect_connected(sent, TARGET, MAX_DEPTH)\n",
    "    for d, items in dep_map.items():\n",
    "        all_hits[sid][d].extend(items)\n",
    "\n",
    "# --- demo print ---------------------------------------------------- #\n",
    "for sid in sorted(all_hits):\n",
    "    print(f\"\\nSentence {sid}: {sents[sid-1]}\")\n",
    "    for d in sorted(all_hits[sid]):\n",
    "        print(f\"  depth {d}:\")\n",
    "        for lem, rel_path in all_hits[sid][d]:\n",
    "            print(f\"      {lem:<10}  {rel_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "pattern = re.compile(\n",
    "    r'([^\\t]+)\\t'      # word form\n",
    "    r'([^\\t]+)\\t'      # lemma\n",
    "    r'([^\\t])[^\\t]*\\t' # POS (UPOS or XPOS)\n",
    "    r'([^\\t]+)\\t'      # ID\n",
    "    r'([^\\t]+)\\t'      # HEAD\n",
    "    r'([^\\t]+)'        # DEPREL\n",
    ")\n",
    "\n",
    "target_lemma = 'miss'\n",
    "target_pos = 'V'\n",
    "corpus_folder = '/home/volt/bach/pilot_data/COHA/10_20_parsed_1_SPOS'\n",
    "output_folder = f'/home/volt/bach/SynFlow/output/{target_lemma}'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "visualisation_folder = f'/home/volt/bach/SynFlow/visualisation/{target_lemma}'\n",
    "if not os.path.exists(visualisation_folder):\n",
    "    os.makedirs(visualisation_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the distribution of different syntactic relationships from the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import SynFlow.arg_explorer\n",
    "importlib.reload(SynFlow.arg_explorer)\n",
    "from SynFlow.arg_explorer import arg_explorer\n",
    "\n",
    "dist = arg_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    max_length=1,\n",
    "    top_n=51,\n",
    "    pattern=pattern,\n",
    "    output_folder=output_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Argument Combination Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 unique full-pattern string for 1 token\n",
    "\n",
    "import importlib\n",
    "import SynFlow.arg_comb_explorer\n",
    "importlib.reload(SynFlow.arg_comb_explorer)\n",
    "from SynFlow.arg_comb_explorer import arg_comb_explorer\n",
    "\n",
    "ctr = arg_comb_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    max_length=1,\n",
    "    top_n=30,\n",
    "    output_folder=output_folder,\n",
    "    pattern=pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rel Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import SynFlow.rel_explorer\n",
    "importlib.reload(SynFlow.rel_explorer)\n",
    "from SynFlow.rel_explorer import rel_explorer\n",
    "\n",
    "triples = rel_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    pattern=pattern,            # or leave None to use default\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    rel=\"pa_parataxis\",\n",
    ")\n",
    "\n",
    "# inspect a few\n",
    "# for sent, ctx_list, path in triples[:10]:\n",
    "#     print(f\"{path:>15}  {' > '.join(ctx_list):20} | {sent}\")\n",
    "\n",
    "for fname, sent, ctx_list, path in triples[:10]:\n",
    "    # ctx_list là một list các \"lemma/pos\", nối bằng ' > ' để in cho dễ nhìn\n",
    "    ctx_chain = \" > \".join(ctx_list)\n",
    "    print(f\"{fname:20} | {path:15} | {ctx_chain:20} | {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Rel Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import SynFlow.full_rel_explorer\n",
    "importlib.reload(SynFlow.full_rel_explorer)\n",
    "from SynFlow.full_rel_explorer import full_rel_explorer\n",
    "\n",
    "triples = full_rel_explorer(\n",
    "    corpus_folder=corpus_folder,\n",
    "    pattern=pattern,            # or leave None to use default\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    rel=\"chi_advmod & chi_aux & chi_nsubj & chi_obj & chi_punct\",\n",
    "    # rel=\"chi_aux & chi_nsubj & chi_obj & chi_punct\",\n",
    "    # rel=\"chi_discourse > chi_punct & chi_punct\",\n",
    "    mode = 'open', # 'open', 'close', 'closeh'\n",
    "    max_check_depth=2\n",
    ")\n",
    "\n",
    "print(len(triples))\n",
    "\n",
    "# inspect a few\n",
    "for fname, sent, found_paths_details_list in triples[:10]:\n",
    "    # found_paths_details_list is a list of (ctx_nodes, path_str) tuples\n",
    "    for ctx_nodes, path_str in found_paths_details_list:\n",
    "        # ctx_nodes is a list of \"lemma/pos\", join using ' > ' to print\n",
    "        ctx_chain = \" > \".join(ctx_nodes)\n",
    "        print(f\"{fname:20} | {path_str:15} | {ctx_chain:20} | {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Target</th>\n",
       "      <th>Slot1</th>\n",
       "      <th>Slot2</th>\n",
       "      <th>Slot3</th>\n",
       "      <th>Slot4</th>\n",
       "      <th>Slot5</th>\n",
       "      <th>Slot6</th>\n",
       "      <th>Slot7</th>\n",
       "      <th>Slot8</th>\n",
       "      <th>...</th>\n",
       "      <th>Slot26</th>\n",
       "      <th>Slot27</th>\n",
       "      <th>Slot28</th>\n",
       "      <th>Slot29</th>\n",
       "      <th>Slot30</th>\n",
       "      <th>Slot31</th>\n",
       "      <th>Slot32</th>\n",
       "      <th>Slot33</th>\n",
       "      <th>Slot34</th>\n",
       "      <th>Slot35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_punct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_punct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; pa_acl:relcl &gt; pa_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_punct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_discourse &gt; chi_punct</td>\n",
       "      <td>&gt; chi_punct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advcl &gt; chi_advmod</td>\n",
       "      <td>&gt; chi_advcl &gt; chi_mark</td>\n",
       "      <td>&gt; chi_advcl &gt; chi_obj</td>\n",
       "      <td>&gt; chi_advcl &gt; chi_obl</td>\n",
       "      <td>&gt; chi_advcl &gt; chi_punct</td>\n",
       "      <td>&gt; chi_advmod &gt; chi_punct</td>\n",
       "      <td>&gt; chi_nsubj &gt; chi_det</td>\n",
       "      <td>&gt; chi_obj &gt; chi_amod</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_cc</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obl &gt; chi_case</td>\n",
       "      <td>&gt; chi_obl &gt; chi_det</td>\n",
       "      <td>&gt; pa_conj &gt; chi_advmod</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod &gt; chi_advmod</td>\n",
       "      <td>&gt; chi_cc</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_punct</td>\n",
       "      <td>&gt; pa_conj &gt; chi_advmod</td>\n",
       "      <td>&gt; pa_conj &gt; chi_aux</td>\n",
       "      <td>&gt; pa_conj &gt; chi_nsubj</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_conj &gt; chi_advmod</td>\n",
       "      <td>&gt; chi_conj &gt; chi_aux</td>\n",
       "      <td>&gt; chi_conj &gt; chi_cc</td>\n",
       "      <td>&gt; chi_conj &gt; chi_iobj</td>\n",
       "      <td>&gt; chi_conj &gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_conj &gt; chi_punct</td>\n",
       "      <td>&gt; chi_conj &gt; chi_xcomp</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_obj &gt; chi_det:predet</td>\n",
       "      <td>&gt; chi_obj &gt; chi_nmod</td>\n",
       "      <td>&gt; chi_obj &gt; chi_nmod:poss</td>\n",
       "      <td>&gt; pa_csubj &gt; chi_conj</td>\n",
       "      <td>&gt; pa_csubj &gt; chi_cop</td>\n",
       "      <td>&gt; pa_csubj &gt; chi_nmod:poss</td>\n",
       "      <td>&gt; pa_csubj &gt; chi_nsubj</td>\n",
       "      <td>&gt; pa_csubj &gt; chi_obl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3342 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency Target                        Slot1                   Slot2  \\\n",
       "0            25   miss                 > chi_advmod               > chi_aux   \n",
       "1            16   miss                    > chi_aux             > chi_nsubj   \n",
       "2            15   miss                    > chi_aux             > chi_nsubj   \n",
       "3             8   miss                 > chi_advmod             > chi_nsubj   \n",
       "4             8   miss  > chi_discourse > chi_punct             > chi_punct   \n",
       "...         ...    ...                          ...                     ...   \n",
       "3337          1   miss     > chi_advcl > chi_advmod  > chi_advcl > chi_mark   \n",
       "3338          1   miss                 > chi_advmod               > chi_aux   \n",
       "3339          1   miss    > chi_advmod > chi_advmod                > chi_cc   \n",
       "3340          1   miss      > chi_conj > chi_advmod    > chi_conj > chi_aux   \n",
       "3341          1   miss   > chi_obj > chi_det:predet    > chi_obj > chi_nmod   \n",
       "\n",
       "                          Slot3                  Slot4  \\\n",
       "0                   > chi_nsubj              > chi_obj   \n",
       "1                     > chi_obj            > chi_punct   \n",
       "2       > pa_acl:relcl > pa_obj                    NaN   \n",
       "3                     > chi_obj            > chi_punct   \n",
       "4                           NaN                    NaN   \n",
       "...                         ...                    ...   \n",
       "3337      > chi_advcl > chi_obj  > chi_advcl > chi_obl   \n",
       "3338                   > chi_cc            > chi_nsubj   \n",
       "3339                > chi_nsubj              > chi_obj   \n",
       "3340        > chi_conj > chi_cc  > chi_conj > chi_iobj   \n",
       "3341  > chi_obj > chi_nmod:poss  > pa_csubj > chi_conj   \n",
       "\n",
       "                        Slot5                       Slot6  \\\n",
       "0                 > chi_punct                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "...                       ...                         ...   \n",
       "3337  > chi_advcl > chi_punct    > chi_advmod > chi_punct   \n",
       "3338                > chi_obj        > chi_obl > chi_case   \n",
       "3339              > chi_punct      > pa_conj > chi_advmod   \n",
       "3340   > chi_conj > chi_nsubj      > chi_conj > chi_punct   \n",
       "3341     > pa_csubj > chi_cop  > pa_csubj > chi_nmod:poss   \n",
       "\n",
       "                       Slot7                   Slot8  ... Slot26 Slot27  \\\n",
       "0                        NaN                     NaN  ...    NaN    NaN   \n",
       "1                        NaN                     NaN  ...    NaN    NaN   \n",
       "2                        NaN                     NaN  ...    NaN    NaN   \n",
       "3                        NaN                     NaN  ...    NaN    NaN   \n",
       "4                        NaN                     NaN  ...    NaN    NaN   \n",
       "...                      ...                     ...  ...    ...    ...   \n",
       "3337   > chi_nsubj > chi_det    > chi_obj > chi_amod  ...    NaN    NaN   \n",
       "3338     > chi_obl > chi_det  > pa_conj > chi_advmod  ...    NaN    NaN   \n",
       "3339     > pa_conj > chi_aux   > pa_conj > chi_nsubj  ...    NaN    NaN   \n",
       "3340  > chi_conj > chi_xcomp               > chi_obj  ...    NaN    NaN   \n",
       "3341  > pa_csubj > chi_nsubj    > pa_csubj > chi_obl  ...    NaN    NaN   \n",
       "\n",
       "     Slot28 Slot29 Slot30 Slot31 Slot32 Slot33 Slot34 Slot35  \n",
       "0       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "3337    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3338    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3339    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3340    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3341    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[3342 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/volt/bach/SynFlow/output/miss/miss_arg_comb_2_hops.csv', sep='&')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volt/bach/SynFlow/SynFlow/trimming.py:54: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[slot_cols] = df[slot_cols].replace(\"\", np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged file to /home/volt/bach/SynFlow/output/miss/miss_arg_comb_2_hops_trimmed.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Target</th>\n",
       "      <th>Slot_1</th>\n",
       "      <th>Slot_2</th>\n",
       "      <th>Slot_3</th>\n",
       "      <th>Slot_4</th>\n",
       "      <th>Slot_5</th>\n",
       "      <th>Slot_6</th>\n",
       "      <th>Slot_7</th>\n",
       "      <th>Slot_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Slot_25</th>\n",
       "      <th>Slot_26</th>\n",
       "      <th>Slot_27</th>\n",
       "      <th>Slot_28</th>\n",
       "      <th>Slot_29</th>\n",
       "      <th>Slot_30</th>\n",
       "      <th>Slot_31</th>\n",
       "      <th>Slot_32</th>\n",
       "      <th>Slot_33</th>\n",
       "      <th>Slot_34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>48</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>28</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_aux</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>22</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>20</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>18</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obj &gt; chi_acl:relcl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obj &gt; chi_acl:relcl</td>\n",
       "      <td>&gt; chi_obj &gt; chi_amod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obj &gt; chi_amod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obj &gt; chi_amod</td>\n",
       "      <td>&gt; chi_obj &gt; chi_nmod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1</td>\n",
       "      <td>miss</td>\n",
       "      <td>&gt; chi_advmod</td>\n",
       "      <td>&gt; chi_nsubj</td>\n",
       "      <td>&gt; chi_nsubj &gt; chi_acl:relcl</td>\n",
       "      <td>&gt; chi_nsubj &gt; chi_compound</td>\n",
       "      <td>&gt; chi_obj</td>\n",
       "      <td>&gt; chi_obl</td>\n",
       "      <td>&gt; chi_obl &gt; chi_case</td>\n",
       "      <td>&gt; chi_obl &gt; chi_det:predet</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3052 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency Target        Slot_1       Slot_2  \\\n",
       "651          48   miss  > chi_advmod    > chi_aux   \n",
       "1644         28   miss     > chi_aux  > chi_nsubj   \n",
       "2789         22   miss     > chi_obj          NaN   \n",
       "2602         20   miss   > chi_nsubj    > chi_obj   \n",
       "1051         18   miss  > chi_advmod  > chi_nsubj   \n",
       "...         ...    ...           ...          ...   \n",
       "1054          1   miss  > chi_advmod  > chi_nsubj   \n",
       "1055          1   miss  > chi_advmod  > chi_nsubj   \n",
       "1057          1   miss  > chi_advmod  > chi_nsubj   \n",
       "1058          1   miss  > chi_advmod  > chi_nsubj   \n",
       "1044          1   miss  > chi_advmod  > chi_nsubj   \n",
       "\n",
       "                           Slot_3                      Slot_4  \\\n",
       "651                   > chi_nsubj                   > chi_obj   \n",
       "1644                    > chi_obj                         NaN   \n",
       "2789                          NaN                         NaN   \n",
       "2602                          NaN                         NaN   \n",
       "1051                    > chi_obj                         NaN   \n",
       "...                           ...                         ...   \n",
       "1054                    > chi_obj   > chi_obj > chi_acl:relcl   \n",
       "1055                    > chi_obj   > chi_obj > chi_acl:relcl   \n",
       "1057                    > chi_obj        > chi_obj > chi_amod   \n",
       "1058                    > chi_obj        > chi_obj > chi_amod   \n",
       "1044  > chi_nsubj > chi_acl:relcl  > chi_nsubj > chi_compound   \n",
       "\n",
       "                    Slot_5     Slot_6                Slot_7  \\\n",
       "651                    NaN        NaN                   NaN   \n",
       "1644                   NaN        NaN                   NaN   \n",
       "2789                   NaN        NaN                   NaN   \n",
       "2602                   NaN        NaN                   NaN   \n",
       "1051                   NaN        NaN                   NaN   \n",
       "...                    ...        ...                   ...   \n",
       "1054                   NaN        NaN                   NaN   \n",
       "1055  > chi_obj > chi_amod        NaN                   NaN   \n",
       "1057                   NaN        NaN                   NaN   \n",
       "1058  > chi_obj > chi_nmod        NaN                   NaN   \n",
       "1044             > chi_obj  > chi_obl  > chi_obl > chi_case   \n",
       "\n",
       "                          Slot_8  ... Slot_25 Slot_26 Slot_27 Slot_28 Slot_29  \\\n",
       "651                          NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1644                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2789                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2602                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1051                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "...                          ...  ...     ...     ...     ...     ...     ...   \n",
       "1054                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1055                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1057                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1058                         NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1044  > chi_obl > chi_det:predet  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     Slot_30 Slot_31 Slot_32 Slot_33 Slot_34  \n",
       "651      NaN     NaN     NaN     NaN     NaN  \n",
       "1644     NaN     NaN     NaN     NaN     NaN  \n",
       "2789     NaN     NaN     NaN     NaN     NaN  \n",
       "2602     NaN     NaN     NaN     NaN     NaN  \n",
       "1051     NaN     NaN     NaN     NaN     NaN  \n",
       "...      ...     ...     ...     ...     ...  \n",
       "1054     NaN     NaN     NaN     NaN     NaN  \n",
       "1055     NaN     NaN     NaN     NaN     NaN  \n",
       "1057     NaN     NaN     NaN     NaN     NaN  \n",
       "1058     NaN     NaN     NaN     NaN     NaN  \n",
       "1044     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[3052 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import SynFlow.trimming\n",
    "importlib.reload(SynFlow.trimming)\n",
    "from SynFlow.trimming import trim_and_merge\n",
    "df_file = '/home/volt/bach/SynFlow/output/miss/miss_arg_comb_2_hops.csv'\n",
    "trimmed_rels = ['chi_punct', 'chi_det', 'pa_parataxis','chi_discourse']\n",
    "trim_and_merge(df_file=df_file, trimmed_rels=trimmed_rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialisations Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /home/volt/bach/SynFlow/output/miss/miss_arg_comb_grouped.json\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import SynFlow.trimming\n",
    "importlib.reload(SynFlow.trimming)\n",
    "from SynFlow.trimming import spe_group\n",
    "\n",
    "df_path = '/home/volt/bach/SynFlow/output/miss/miss_arg_comb_2_hops_trimmed.csv'\n",
    "tree = spe_group(df_path, output_folder=output_folder, target_lemma=target_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Slot df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote slot‐fillers to /home/volt/bach/SynFlow/output/miss/miss_samples_all_slots.csv (414 rows), dropped 3178 tokens.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import SynFlow.get_embeddings\n",
    "importlib.reload(SynFlow.get_embeddings)\n",
    "from SynFlow.get_embeddings import build_slot_df\n",
    "\n",
    "df_slots = build_slot_df(\n",
    "    corpus_folder=corpus_folder,\n",
    "    template='[chi_nsubj|chi_obl:agent]',\n",
    "    target_lemma=target_lemma,\n",
    "    target_pos=target_pos,\n",
    "    pattern=pattern,\n",
    "    freq_path='/home/volt/bach/SynFlow/COHA_10_20_lemma_deprel_freq.txt',\n",
    "    freq_min=1,\n",
    "    freq_max=100_000_000,\n",
    "    filtered_pos=['P'],\n",
    "    filler_format='lemma/deprel',\n",
    "    out_template_csv=f'{output_folder}/{target_lemma}_samples_all_slots.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the general slots DataFrame\n",
    "import importlib\n",
    "import SynFlow.get_embeddings\n",
    "importlib.reload(SynFlow.get_embeddings)\n",
    "from SynFlow.get_embeddings import sample_slot_df\n",
    "n = 500\n",
    "df_sample = sample_slot_df(\n",
    "    input_csv=f\"{output_folder}/{target_lemma}_samples_all_slots.csv\",\n",
    "    output_csv=f\"{visualisation_folder}/{target_lemma}_samples_{n}_slots.csv\",\n",
    "    n=n,\n",
    "    seed=42,\n",
    "    mode= 'NA'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template='[chi_nsubj][chi_obj][chi_obl > chi_case]'\n",
    "# slots     = template.strip(\"[]\").split(\"][\")\n",
    "# print(slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import SynFlow.get_embeddings\n",
    "importlib.reload(SynFlow.get_embeddings)\n",
    "from SynFlow.get_embeddings import build_embeddings\n",
    "n = 1000\n",
    "df_emb = build_embeddings(\n",
    "    df_templates=pd.read_csv(f'{visualisation_folder}/{target_lemma}_samples_{n}_slots.csv', index_col=0), # df_slots,\n",
    "    type_embedding_path='/home/volt/bach/SynFlow/type_embedding/coha_10_20_w2v.csv',\n",
    "    dims=300,\n",
    "    slot_mode='mult',\n",
    "    tok_mode='mult',\n",
    "    out_embedding=f'{visualisation_folder}/{target_lemma}_samples_{n}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/volt/bach/SynFlow/type_embedding/coha_10_20_w2v.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import SynFlow.compute_dist\n",
    "importlib.reload(SynFlow.compute_dist)\n",
    "from SynFlow.compute_dist import compute_cosine_distmtx\n",
    "\n",
    "# Example usage:\n",
    "df_emb = pd.read_csv(f\"{visualisation_folder}/{target_lemma}_samples_{n}_embeddings.csv\", index_col=0)\n",
    "dist_df = compute_cosine_distmtx(df_emb)\n",
    "dist_df.to_csv(f\"{visualisation_folder}/{target_lemma}_samples_{n}_distance_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with the cosine similarity\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity_np(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two vectors using NumPy.\n",
    "\n",
    "    Args:\n",
    "        vec1 (numpy.ndarray or list): The first vector.\n",
    "        vec2 (numpy.ndarray or list): The second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: The cosine similarity between the two vectors.\n",
    "               Returns 0 if either vector has a magnitude of zero.\n",
    "    \"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0  # Or handle as an error, depending on desired behavior\n",
    "    else:\n",
    "        return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Example Usage:\n",
    "vector_a = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "vector_b = [3, 5, 7, 9, 11, 13, 15, 17]\n",
    "\n",
    "vector_c = [5, 6, 7, 8, 1, 2, 3, 4]\n",
    "vector_d = [11, 13, 15, 17, 3, 5, 7, 9]\n",
    "\n",
    "# vector_a = [1, 1, 1, 1, 2, 2, 2, 2]\n",
    "# vector_b = [1, 1, 1, 1, 2, 2, 2, 2]\n",
    "\n",
    "similarity = cosine_similarity_np(vector_a, vector_b)\n",
    "print(f\"Cosine Similarity (NumPy): {similarity}\")\n",
    "\n",
    "similarity = cosine_similarity_np(vector_c, vector_d)\n",
    "print(f\"Cosine Similarity (NumPy): {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import SynFlow.get_contexts\n",
    "importlib.reload(SynFlow.get_contexts)\n",
    "from SynFlow.get_contexts import corpus_handler, get_contexts\n",
    "import re\n",
    "pattern = re.compile(\n",
    "    r'([^\\t]+)\\t'      # FORM\n",
    "    r'([^\\t]+)\\t'      # LEMMA\n",
    "    r'([^\\t])[^\\t]*\\t' # POS\n",
    "    r'([^\\t]+)\\t'      # ID\n",
    "    r'([^\\t]+)\\t'      # HEAD\n",
    "    r'([^\\t]+)'        # DEPREL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "slots_df = pd.read_csv(f\"{visualisation_folder}/{target_lemma}_samples_{n}_slots.csv\", index_col=0)\n",
    "\n",
    "# Now attach contexts:\n",
    "context_df = get_contexts(\n",
    "    slots_df=slots_df,\n",
    "    corpus_path=\"/home/volt/bach/pilot_data/COHA/10_20_parsed_1_SPOS\",\n",
    "    pattern=pattern,\n",
    "    output_path=f\"{visualisation_folder}/{target_lemma}_samples_{n}_contexts.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hdbscan\n",
    "\n",
    "def hdbscan_clustering(dist_df: pd.DataFrame,\n",
    "                          min_cluster_size: int = 5,\n",
    "                          min_samples: int = None,\n",
    "                          cluster_selection_epsilon: float = 0.0,\n",
    "                          cluster_selection_method: str = 'eom',\n",
    "                         ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a precomputed distance matrix `dist_df` (square DataFrame indexed and\n",
    "    columned by token IDs), run HDBSCAN (metric='precomputed') and return a new\n",
    "    DataFrame with two columns:\n",
    "      • 'token'   : the token ID (index of dist_df)\n",
    "      • 'cluster' : the HDBSCAN cluster label (-1 for noise)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dist_df : pd.DataFrame\n",
    "        Square distance matrix (n × n), index and columns are identical token IDs.\n",
    "    min_cluster_size : int, default=5\n",
    "        The minimum size of clusters; see HDBSCAN docs.\n",
    "    min_samples : int or None, default=None\n",
    "        Controls how conservative the clustering is; if None, it defaults to\n",
    "        min_cluster_size.\n",
    "    cluster_selection_epsilon : float, default=0.0\n",
    "        A distance threshold: clusters below this distance can be split off.\n",
    "    cluster_selection_method : {'eom','leaf'}, default='eom'\n",
    "        How to select clusters from the condensed tree.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with columns ['id','cluster'], index 0..n-1\n",
    "    \"\"\"\n",
    "    # Extract the numpy distance matrix\n",
    "    D = dist_df.values\n",
    "    # Initialize HDBSCAN with precomputed distances\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        metric='precomputed',\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "        cluster_selection_method=cluster_selection_method\n",
    "    )\n",
    "    # Fit on the distance matrix\n",
    "    clusterer.fit(D)\n",
    "    labels = clusterer.labels_  # array of length n, -1 means noise\n",
    "\n",
    "    # Prefix each label with 'c'\n",
    "    clusters_prefixed = [f\"c{lab}\" for lab in labels]\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'id': dist_df.index,\n",
    "        'clusters': clusters_prefixed\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose you already computed dist_df (square DataFrame with token IDs as index & columns)\n",
    "dist_df = pd.read_csv(fr'{visualisation_folder}/{target_lemma}_samples_{n}_distance_matrix.csv', index_col=0)\n",
    "\n",
    "# Cluster with HDBSCAN\n",
    "cluster_df = hdbscan_clustering(\n",
    "    dist_df,\n",
    "    min_cluster_size=10,\n",
    "    min_samples=10\n",
    ")\n",
    "\n",
    "# Save to CSV if desired\n",
    "cluster_df.to_csv(fr'{visualisation_folder}/{target_lemma}_samples_{n}_clusters.csv', index=False)\n",
    "\n",
    "# Merge to context\n",
    "context_df = pd.read_csv(fr'{visualisation_folder}/{target_lemma}_samples_{n}_contexts.csv', index_col=0)\n",
    "cluster_context_df = context_df.merge(cluster_df, left_index=True, right_on='id')\n",
    "\n",
    "# Save to CSV if desired\n",
    "cluster_context_df.to_csv(fr'{visualisation_folder}/{target_lemma}_samples_{n}_clusters_contexts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Coordinates with tsne, umap, mds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import SynFlow.get_coordinates\n",
    "importlib.reload(SynFlow.get_coordinates)\n",
    "from SynFlow.get_coordinates import get_token_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "dist_df = pd.read_csv(f'{visualisation_folder}/{target_lemma}_samples_{n}_distance_matrix.csv', index_col=0)\n",
    "coord_tsne = get_token_coordinates(lemma=f'{target_lemma}_samples', dist_df=dist_df, method='tsne', perplexity=30, output_path=visualisation_folder, n = n)\n",
    "# coord_mds  = get_token_coordinates(lemma=f'{target_lemma}_samples', dist_df=dist_df, method='mds', max_iter=300, output_path=visualisation_folder, n = n)\n",
    "coord_umap = get_token_coordinates(lemma=f'{target_lemma}_samples', dist_df=dist_df, method='umap', n_neighbors=30, min_dist=0.1, output_path=visualisation_folder, n = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise with plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import SynFlow.visualisation\n",
    "importlib.reload(SynFlow.visualisation)\n",
    "from SynFlow.visualisation import get_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_coords = fr'{visualisation_folder}/{target_lemma}_samples_{n}_tsne.csv'\n",
    "input_ctxs = fr'{visualisation_folder}/{target_lemma}_samples_{n}_clusters_contexts.csv'\n",
    "\n",
    "get_token_ids(input_coords, input_ctxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
